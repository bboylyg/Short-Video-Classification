{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of videos: 300\n",
      "\n",
      "Number of videos in training data: 20\n",
      "Number of videos in validation data: 12\n",
      "Number of videos in test data: 38\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Loading the data\n",
    "# Load text files with categories as subfolder names.\n",
    "raw_data = load_files(r'E:/training_lib_KTH', shuffle=False)\n",
    "files = raw_data['filenames']\n",
    "targets = raw_data['target']\n",
    "# Randomly dividing the whole data into training (66.67%) and testing (33.33%) data \n",
    "train_files, test_files, train_targets, test_targets = train_test_split(files, targets, test_size=1/8, random_state=191)\n",
    "\n",
    "# Taking ~25% of the training data for validation\n",
    "valid_files = train_files[250:]\n",
    "valid_targets = train_targets[250:]\n",
    "\n",
    "# Remaining data will be used for training the model\n",
    "train_files = train_files[:20]\n",
    "train_targets = train_targets[:20]\n",
    "\n",
    "# Generic details about the data\n",
    "\n",
    "print('Total number of videos:', len(files))\n",
    "print('\\nNumber of videos in training data:', train_files.shape[0])\n",
    "print('Number of videos in validation data:', valid_files.shape[0])\n",
    "print('Number of videos in test data:', test_files.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:/training_lib_KTH\\\\boxing\\\\person03_boxing_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person03_boxing_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person04_boxing_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person04_boxing_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person04_boxing_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person04_boxing_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person05_boxing_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person05_boxing_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person05_boxing_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person05_boxing_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person06_boxing_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person06_boxing_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person06_boxing_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person06_boxing_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person07_boxing_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person07_boxing_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person07_boxing_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person07_boxing_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person08_boxing_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person08_boxing_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person08_boxing_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person08_boxing_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person09_boxing_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person09_boxing_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person09_boxing_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person09_boxing_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person10_boxing_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person10_boxing_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person10_boxing_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person10_boxing_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person13_boxing_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person13_boxing_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person14_boxing_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person14_boxing_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person15_boxing_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person15_boxing_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person16_boxing_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person16_boxing_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person16_boxing_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person16_boxing_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person17_boxing_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person17_boxing_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person17_boxing_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person17_boxing_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person18_boxing_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person18_boxing_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person18_boxing_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person18_boxing_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person19_boxing_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\boxing\\\\person19_boxing_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person05_handclapping_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person06_handclapping_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person06_handclapping_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person06_handclapping_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person06_handclapping_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person07_handclapping_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person07_handclapping_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person07_handclapping_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person07_handclapping_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person08_handclapping_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person08_handclapping_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person08_handclapping_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person08_handclapping_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person09_handclapping_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person09_handclapping_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person09_handclapping_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person10_handclapping_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person10_handclapping_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person10_handclapping_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person10_handclapping_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person11_handclapping_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person11_handclapping_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person11_handclapping_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person12_handclapping_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person12_handclapping_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person12_handclapping_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person12_handclapping_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person13_handclapping_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person13_handclapping_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person13_handclapping_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person14_handclapping_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person14_handclapping_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person14_handclapping_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person15_handclapping_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person15_handclapping_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person15_handclapping_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person15_handclapping_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person18_handclapping_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person19_handclapping_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person19_handclapping_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person19_handclapping_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person19_handclapping_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person20_handclapping_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person20_handclapping_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person20_handclapping_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person20_handclapping_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person21_handclapping_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person21_handclapping_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person21_handclapping_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handclapping\\\\person21_handclapping_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person06_handwaving_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person06_handwaving_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person06_handwaving_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person06_handwaving_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person07_handwaving_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person07_handwaving_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person07_handwaving_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person07_handwaving_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person08_handwaving_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person08_handwaving_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person08_handwaving_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person08_handwaving_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person09_handwaving_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person09_handwaving_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person09_handwaving_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person09_handwaving_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person10_handwaving_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person10_handwaving_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person10_handwaving_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person10_handwaving_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person11_handwaving_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person11_handwaving_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person11_handwaving_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person11_handwaving_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person12_handwaving_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person12_handwaving_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person12_handwaving_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person12_handwaving_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person13_handwaving_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person13_handwaving_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person16_handwaving_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person16_handwaving_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person16_handwaving_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person16_handwaving_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person17_handwaving_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person17_handwaving_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person17_handwaving_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person17_handwaving_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person18_handwaving_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person18_handwaving_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person18_handwaving_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person18_handwaving_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person19_handwaving_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person19_handwaving_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person19_handwaving_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person19_handwaving_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person19_walking_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person20_handwaving_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person20_handwaving_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\handwaving\\\\person20_handwaving_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person10_jogging_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person11_jogging_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person11_jogging_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person11_jogging_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person11_jogging_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person12_jogging_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person12_jogging_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person12_jogging_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person12_jogging_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person13_jogging_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person13_jogging_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person13_jogging_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person13_jogging_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person14_jogging_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person14_jogging_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person14_jogging_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person14_jogging_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person15_jogging_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person15_jogging_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person15_jogging_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person15_jogging_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person16_jogging_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person16_jogging_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person16_jogging_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person16_jogging_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person17_jogging_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person17_jogging_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person17_jogging_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person17_jogging_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person18_jogging_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person18_jogging_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person18_jogging_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person18_jogging_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person19_jogging_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person19_jogging_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person19_jogging_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person19_jogging_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person20_jogging_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person20_jogging_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person20_jogging_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person20_jogging_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person21_jogging_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person21_jogging_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person21_jogging_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person21_jogging_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person22_jogging_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person22_jogging_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person22_jogging_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person22_jogging_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\jogging\\\\person23_jogging_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person06_running_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person06_running_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person06_running_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person06_running_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person07_running_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person07_running_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person07_running_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person07_running_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person07_walking_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person07_walking_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person07_walking_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person07_walking_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person08_running_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person08_running_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person08_running_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person08_running_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person09_running_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person09_running_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person09_running_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person09_running_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person15_running_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person15_running_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person15_running_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person15_running_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person16_running_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person16_running_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person16_running_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person16_running_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person17_running_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person17_running_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person17_running_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person17_running_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person18_running_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person18_running_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person18_running_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person18_running_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person19_running_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person19_running_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person19_running_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person19_running_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person20_running_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person20_running_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person20_running_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person20_running_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person21_running_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person21_running_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person21_running_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person21_running_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person22_running_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\running\\\\person22_running_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person06_walking_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person06_walking_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person06_walking_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person08_walking_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person08_walking_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person08_walking_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person08_walking_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person09_walking_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person09_walking_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person09_walking_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person10_walking_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person10_walking_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person10_walking_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person10_walking_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person11_walking_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person11_walking_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person11_walking_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person12_walking_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person12_walking_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person12_walking_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person13_walking_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person13_walking_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person13_walking_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person14_walking_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person14_walking_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person14_walking_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person14_walking_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person15_walking_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person15_walking_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person15_walking_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person16_walking_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person16_walking_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person16_walking_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person17_walking_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person17_walking_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person17_walking_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person17_walking_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person18_walking_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person18_walking_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person18_walking_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person19_walking_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person19_walking_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person19_walking_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person20_walking_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person20_walking_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person20_walking_d3_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person20_walking_d4_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person21_walking_d1_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person21_walking_d2_uncomp.avi'\n",
      " 'E:/training_lib_KTH\\\\walking\\\\person21_walking_d3_uncomp.avi']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5]\n",
      "['boxing', 'handclapping', 'handwaving', 'jogging', 'running', 'walking']\n"
     ]
    }
   ],
   "source": [
    "print(files)  # 打印所有文件名（eg.'E:/training_lib_KTH\\\\walking\\\\person19_walking_d2_uncomp.avi'）\n",
    "print(targets)  # targets = raw_data['target'] :[0 1 2 3 4 5 ]类别被自动转换为数值\n",
    "print(raw_data['target_names'])  # ['boxing', 'handclapping', 'handwaving', 'jogging', 'running', 'walking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.utils import to_categorical\n",
    "from utils import Videos\n",
    "\n",
    "def load_frame(train_files, train_targets, valid_files, valid_targets, test_files,test_targets):\n",
    "    # An object of the class `Videos` to load the data in the required format\n",
    "    reader = Videos(target_size=(32, 32), \n",
    "                    to_gray=True, \n",
    "                    max_frames=200, \n",
    "                    extract_frames='middle', \n",
    "                    normalize_pixels=(0, 1))\n",
    "\n",
    "    # Reading training videos and one-hot encoding the training labels\n",
    "    X_train = reader.read_videos(train_files)\n",
    "    y_train = to_categorical(train_targets, num_classes=6)\n",
    "    print('Shape of training data:', X_train.shape)\n",
    "    print('Shape of training labels:', y_train.shape)\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    # Reading validation videos and one-hot encoding the validation labels\n",
    "    X_valid = reader.read_videos(valid_files)\n",
    "    y_valid = to_categorical(valid_targets, num_classes=6)\n",
    "    print('Shape of validation data:', X_valid.shape)\n",
    "    print('Shape of validation labels:', y_valid.shape)\n",
    "    time.sleep(0.01)\n",
    "    \n",
    "    # Reading testing videos and one-hot encoding the testing labels\n",
    "    X_test = reader.read_videos(test_files)\n",
    "    y_test = to_categorical(test_targets, num_classes=6)\n",
    "    print('Shape of testing data:', X_test.shape)\n",
    "    print('Shape of testing labels:', y_test.shape)\n",
    "\n",
    "    return (X_train, y_train, X_valid, y_valid, X_test,y_test)\n",
    "#     return (X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:15<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (20, 200, 32, 32, 1)\n",
      "Shape of training labels: (20, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:07<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of validation data: (12, 200, 32, 32, 1)\n",
      "Shape of validation labels: (12, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:24<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of testing data: (38, 200, 32, 32, 1)\n",
      "Shape of testing labels: (38, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test,y_test = load_frame(train_files, train_targets, valid_files, valid_targets, test_files,test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(20, 200, 32, 32, 1)\n",
      "[[0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(X_train.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define Model\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv3D, MaxPooling3D, GlobalAveragePooling3D, Flatten, BatchNormalization\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "n_classes=6\n",
    "nmodel=3\n",
    "\n",
    "\n",
    "def create_3dcnn(X_train,n_classes):\n",
    "   \n",
    "    # Using the Sequential Model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Adding Alternate convolutional and pooling layers\n",
    "    model.add(Conv3D(filters=16, kernel_size=(3, 3, 3), strides=(3, 1, 1), padding='same', activation='relu', \n",
    "                     input_shape=X_train.shape[1:]))\n",
    "    # model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=2, strides=(1, 2, 2), padding='same'))\n",
    "\n",
    "    model.add(Conv3D(filters=64, kernel_size=(3, 3, 3), strides=(3, 1, 1), padding='valid', activation='relu'))\n",
    "    # model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=2, strides=(1, 2, 2), padding='same'))\n",
    "\n",
    "    model.add(Conv3D(filters=256, kernel_size=(3, 3, 3), strides=(3, 1, 1), padding='same', activation='relu'))\n",
    "    # model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=2, strides=(1, 2, 2), padding='same'))\n",
    "\n",
    "   \n",
    "    model.add(Flatten())\n",
    "    # Hidden layer\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Dropout Layer\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "#     plot_model(model, to_file=\"F://C3D_simple.png\", show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 67, 32, 32, 16)    448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 67, 32, 32, 16)    64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 67, 16, 16, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 22, 14, 14, 64)    27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 14, 14, 64)    256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 22, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 8, 7, 7, 256)      442624    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 7, 7, 256)      1024      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 8, 4, 4, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2097216   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 2,569,990\n",
      "Trainable params: 2,569,190\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1d46cb3cac8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_3dcnn(X_train,n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only used plot_model\n",
    "\n",
    "from keras.layers import average\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('AGG')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from plot_history import plot_history\n",
    "\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "def ensemble_model(X_train, n_classes=6, nmodel=2):\n",
    "    models=[]\n",
    "    for i in range(nmodel):\n",
    "        print('model_{}:'.format(i))\n",
    "        model_ = create_3dcnn(X_train,n_classes)\n",
    "        models.append(model_)\n",
    "        print('[INFO] finish create model_{}'.format(i))\n",
    "        \n",
    "        #append添加到列表最后面，通过model[-1]访问\n",
    "        models[-1].compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    model_inputs = [Input(shape=X_train.shape[1:]) for _ in range (nmodel)]   #定义了一个input层\n",
    "    model_outputs = [models[i](model_inputs[i]) for i in range (nmodel)]   #所有model添加input，models[i](model_inputs[i])Keras API添加模型形式\n",
    "    model_outputs = average(inputs=model_outputs)  #具体模型结构参考plot图像\n",
    "    model = Model(inputs=model_inputs, outputs=model_outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "#     plot_model(model, to_file=\"F://C3D_ensemble_3.png\", show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "ensemble_model(X_train, n_classes=6, nmodel=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import average\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('AGG')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from plot_history import plot_history\n",
    "\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "def ensemble_model(X_train, n_classes=6, nmodel=2):\n",
    "    models=[]\n",
    "    for i in range(nmodel):\n",
    "        print('model_{}:'.format(i))\n",
    "        model_ = create_3dcnn(X_train,n_classes)\n",
    "        models.append(model_)\n",
    "        print('[INFO] finish create model_{}'.format(i))\n",
    "        \n",
    "        #append添加到列表最后面，通过model[-1]访问\n",
    "        models[-1].compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam', metrics=['accuracy'])\n",
    "#         checkpoint = ModelCheckpoint(filepath='E://Model_Weights//Model_weights_ensemble_{}.best.hdf5'.format(i), save_best_only=True, verbose=1)\n",
    "\n",
    "        # Training the model for 40 epochs\n",
    "        history = models[-1].fit(X_train, y_train, batch_size=16, epochs=5, verbose=2,\n",
    "                            validation_data=(X_valid, y_valid),  shuffle=True)\n",
    "        \n",
    "#         history = models[-1].fit(X_train, y_train, validation_data=(\n",
    "#             X_test, Y_test), batch_size=args.batch, nb_epoch=args.epoch, verbose=1, shuffle=True)\n",
    "\n",
    "#         plot_history(history , output, i)\n",
    "        result_dir='F://'\n",
    "        plt.plot(history.history['acc'], marker='.')\n",
    "        plt.plot(history.history['val_acc'], marker='.')\n",
    "        plt.title('model accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.grid()\n",
    "        plt.legend(['acc', 'val_acc'], loc='lower right')\n",
    "        plt.savefig(os.path.join(result_dir, 'model_{}_accuracy.png'.format(i)))\n",
    "        plt.close()\n",
    "\n",
    "        plt.plot(history.history['loss'], marker='.')\n",
    "        plt.plot(history.history['val_loss'], marker='.')\n",
    "        plt.title('model loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.grid()\n",
    "        plt.legend(['loss', 'val_loss'], loc='upper right')\n",
    "        plt.savefig(os.path.join(result_dir, 'model_{}_loss.png'.format(i)))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    model_inputs = [Input(shape=X_train.shape[1:]) for _ in range (nmodel)]   #定义了一个input层\n",
    "    model_outputs = [models[i](model_inputs[i]) for i in range (nmodel)]   #所有model添加input，models[i](model_inputs[i])Keras API添加模型形式\n",
    "    model_outputs = average(inputs=model_outputs)  #具体模型结构参考plot图像\n",
    "    model = Model(inputs=model_inputs, outputs=model_outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    output='E://Model_Weights'\n",
    "    model_json=model.to_json()\n",
    "    with open(os.path.join(output, 'ensemble_3dcnnmodel.json'), 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(os.path.join(output, 'ensemble_3dcnnmodel.hd5'))\n",
    "    \n",
    "#     loss, acc=model.evaluate([X_test]*nmodel, Y_test, verbose=2)\n",
    "#     with open(os.path.join(args.output, 'result.txt'), 'w') as f:\n",
    "#         f.write('Test loss: {}\\nTest accuracy:{}'.format(loss, acc))\n",
    "\n",
    "#     print('merged model:')\n",
    "#     print('Test loss:', loss)\n",
    "#     print('Test accuracy:', acc)\n",
    "    #model.summary()\n",
    "    #plot_model(model, to_file=\"F://C3D_ensemble.png\", show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ensemble_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-44f8fd7704c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mensemble_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ensemble_model' is not defined"
     ]
    }
   ],
   "source": [
    "ensemble_model(X_train, n_classes=6, nmodel=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged model:\n",
      "Test loss: 4.575178748682926\n",
      "Test accuracy: 0.21052631657374532\n"
     ]
    }
   ],
   "source": [
    "# 重新加载模型\n",
    "\n",
    "# del model\n",
    "# model reconstruction from JSON:\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "nmodel=3\n",
    "\n",
    "#从JSON文件中加载模型\n",
    "json_file = open('E:\\\\Model_Weights\\\\ensemble_3dcnnmodel.json', 'r')\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    " \n",
    "new_model = model_from_json(model_json)\n",
    "new_model.load_weights('E:\\\\Model_Weights\\\\ensemble_3dcnnmodel.hd5')\n",
    " \n",
    "#编译模型\n",
    "new_model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    " \n",
    "#评估加载之后的模型\n",
    "loss, acc=new_model.evaluate([X_test]*nmodel, y_test, verbose=0)\n",
    "# with open(os.path.join(args.output, 'result.txt'), 'w') as f:\n",
    "#     f.write('Test loss: {}\\nTest accuracy:{}'.format(loss, acc))\n",
    "\n",
    "print('merged model:')\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SoccerJuggling.avi']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (1, 10, 32, 32, 1)\n",
      "after:  (1, 32, 32, 10, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\94009\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1109: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(activation=\"relu\", batch_input_shape=[None, 32,..., data_format=\"channels_last\", input_dtype=\"float32\", bias_regularizer=None, use_bias=True, kernel_constraint=None, padding=\"same\", kernel_regularizer=None, name=\"convolution3d_1\", kernel_size=(3, 3, 3), bias_constraint=None, strides=[1, 1, 1], filters=32, kernel_initializer=\"glorot_uniform\", activity_regularizer=None, trainable=True)`\n",
      "  return cls(**config)\n",
      "C:\\Users\\94009\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1109: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(activation=\"relu\", data_format=\"channels_last\", bias_regularizer=None, use_bias=True, kernel_constraint=None, padding=\"same\", kernel_regularizer=None, name=\"convolution3d_2\", kernel_size=(3, 3, 3), bias_constraint=None, filters=32, strides=[1, 1, 1], kernel_initializer=\"glorot_uniform\", activity_regularizer=None, trainable=True)`\n",
      "  return cls(**config)\n",
      "C:\\Users\\94009\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1109: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(padding=\"same\", trainable=True, strides=[3, 3, 3], name=\"maxpooling3d_1\", data_format=\"channels_last\", pool_size=[3, 3, 3])`\n",
      "  return cls(**config)\n",
      "C:\\Users\\94009\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1109: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.25, name=\"dropout_1\", trainable=True)`\n",
      "  return cls(**config)\n",
      "C:\\Users\\94009\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1109: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(activation=\"relu\", data_format=\"channels_last\", bias_regularizer=None, use_bias=True, kernel_constraint=None, padding=\"same\", kernel_regularizer=None, name=\"convolution3d_3\", kernel_size=(3, 3, 3), bias_constraint=None, filters=64, strides=[1, 1, 1], kernel_initializer=\"glorot_uniform\", activity_regularizer=None, trainable=True)`\n",
      "  return cls(**config)\n",
      "C:\\Users\\94009\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1109: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(activation=\"relu\", data_format=\"channels_last\", bias_regularizer=None, use_bias=True, kernel_constraint=None, padding=\"same\", kernel_regularizer=None, name=\"convolution3d_4\", kernel_size=(3, 3, 3), bias_constraint=None, filters=64, strides=[1, 1, 1], kernel_initializer=\"glorot_uniform\", activity_regularizer=None, trainable=True)`\n",
      "  return cls(**config)\n",
      "C:\\Users\\94009\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1109: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(padding=\"same\", trainable=True, strides=[3, 3, 3], name=\"maxpooling3d_2\", data_format=\"channels_last\", pool_size=[3, 3, 3])`\n",
      "  return cls(**config)\n",
      "C:\\Users\\94009\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1109: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.25, name=\"dropout_2\", trainable=True)`\n",
      "  return cls(**config)\n",
      "C:\\Users\\94009\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1109: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_constraint=None, activation=\"relu\", input_dim=2048, kernel_regularizer=None, use_bias=True, bias_regularizer=None, bias_constraint=None, units=512, kernel_initializer=\"normal\", activity_regularizer=None, name=\"dense_1\", trainable=True)`\n",
      "  return cls(**config)\n",
      "C:\\Users\\94009\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1109: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5, name=\"dropout_3\", trainable=True)`\n",
      "  return cls(**config)\n",
      "C:\\Users\\94009\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1109: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_constraint=None, activation=\"linear\", input_dim=512, kernel_regularizer=None, use_bias=True, bias_regularizer=None, bias_constraint=None, units=10, kernel_initializer=\"normal\", activity_regularizer=None, name=\"dense_2\", trainable=True)`\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: [0.11271197 0.05828283 0.1516908  0.06739166 0.07793269 0.04127639\n",
      " 0.03408469 0.39577597 0.03976038 0.02109262]\n",
      "j: 7\n",
      "SoccerJuggling: 39.58%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from utils import Videos\n",
    "\n",
    "\n",
    "train_files='SoccerJuggling.avi'\n",
    "\n",
    "sample = [train_files]\n",
    "print(sample)\n",
    "\n",
    "# An object of the class `Videos` to load the data in the required format\n",
    "reader = Videos(target_size=(32, 32), \n",
    "                to_gray=True, \n",
    "                max_frames=10, \n",
    "                extract_frames='middle', \n",
    "                normalize_pixels=(0, 1))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# After pre-processing\n",
    "X_sample = reader.read_videos(sample)\n",
    "# y_train = to_categorical(train_targets, num_classes=6)\n",
    "print('Shape of training data:', X_sample.shape)\n",
    "# print('Shape of training labels:', y_train.shape)\n",
    "# Displaying the first frame of the first processed video from the training data\n",
    "plt.imshow(np.squeeze(X_sample[0][0], axis=2), cmap='gray')\n",
    "\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "X = np.transpose(X_sample, ( 0, 2,3, 1,4))\n",
    "print('after: ', X.shape)\n",
    "\n",
    "# X = X_sample.reshape((X_sample.shape[0], 32, 32, 10, 1))\n",
    "\n",
    "\n",
    "#从JSON文件中加载模型\n",
    "json_file = open('E:\\\\ucf101_3dcnnmodel.json', 'r')\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    " \n",
    "new_model = model_from_json(model_json)\n",
    "new_model.load_weights('E:\\\\ucf101_3dcnnmodel.hd5')\n",
    "\n",
    "\n",
    "classes=['BandMarching',\n",
    "'CleanAndJerk',\n",
    "'TennisSwing',\n",
    "'FrisbeeCatch',\n",
    "'TaiChi',\n",
    "'HeadMassage',\n",
    "'BoxingSpeedBag',\n",
    "'SoccerJuggling',\n",
    "'PlayingPiano',\n",
    "'PlayingSitar',\n",
    "]\n",
    "\n",
    "\n",
    "predictions = new_model.predict([X],batch_size=1)[0]\n",
    "print('predictions:', predictions)\n",
    "j = predictions.argmax(axis=0)\n",
    "print('j:', j)\n",
    "\n",
    "label = classes[j]\n",
    "proba = predictions[j] * 100\n",
    "\n",
    "label = \"{}: {:.2f}%\".format(label, proba)\n",
    "print(label)\n",
    "\n",
    "# import cv2\n",
    "\n",
    "# # train_files='boxing.avi'\n",
    "\n",
    "# cap = cv2.VideoCapture(train_files)\n",
    "\n",
    "# count = 0\n",
    "# video_imgs = []\n",
    "\n",
    "# predicted_label = 0\n",
    "# classes = {}\n",
    "# flag = False\n",
    "\n",
    "\n",
    "# while True:\n",
    "\n",
    "#     ret, img = cap.read()\n",
    "#     if type(img) == type(None):\n",
    "#         break\n",
    "#     float_img = img.astype(np.float32)\n",
    "#     video_imgs.append(float_img)\n",
    "#     count += 1\n",
    "#     if count == 10:\n",
    "\n",
    "#         count = 0\n",
    "#         video_imgs = []\n",
    "#         flag = True\n",
    "\n",
    "#     if flag:\n",
    "#         label_color = (0, 0, 255)\n",
    "#         cv2.putText(img, label, (10, 15),\n",
    "#                     cv2.FONT_HERSHEY_TRIPLEX, 0.5, label_color,\n",
    "#                     1, False)\n",
    "#     cv2.namedWindow('video',cv2.WINDOW_NORMAL)\n",
    "#     cv2.imshow('video', img)\n",
    "\n",
    "#     if cv2.waitKey(33) == 27:\n",
    "#         break\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.evaluate 用于评估您训练的模型。它的输出是准确度或损失，而不是对输入数据的预测。\n",
    "\n",
    "## model.predict 实际预测，其输出是目标值，根据输入数据预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "[1 0 1 2 5 1 3 1 4 5 4 1 0 2 2 2 2 3 2 3 1 0 2 0 5 1 5 0 1 4 4 0 5 0 3 2 3\n",
      " 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\94009\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         7\n",
      "          1       0.00      0.00      0.00         8\n",
      "          2       0.21      1.00      0.35         8\n",
      "          3       0.00      0.00      0.00         6\n",
      "          4       0.00      0.00      0.00         4\n",
      "          5       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.04      0.21      0.07        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 示例用法\n",
    "# from sklearn.metrics import classification_report\n",
    "# y_true = [0, 1, 2, 2, 2]\n",
    "# y_pred = [0, 0, 2, 2, 1]\n",
    "# target_names = ['class 0', 'class 1', 'class 2']\n",
    "# print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "labelNames = [\"0\", \"1\", \"2\", \"3\", \"4\",\"5\"]\n",
    "# 评估模型\n",
    "predictions = new_model.predict([X_test]*nmodel,batch_size=1)\n",
    "print(predictions.argmax(axis=1))\n",
    "print(y_test.argmax(axis=1))\n",
    "# 模型结果\n",
    "print(classification_report(y_test.argmax(axis=1),predictions.argmax(axis=1),target_names=labelNames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# voting ：Predict labels with models\n",
    "labels = []\n",
    "for m in models:\n",
    "    predicts = np.argmax(m.predict(test), axis=1)\n",
    "    labels.append(predicts)\n",
    "    \n",
    "# Ensemble with voting\n",
    "labels = np.array(labels)\n",
    "labels = np.transpose(labels, (1, 0))\n",
    "# mode众数，出现次数最多的\n",
    "labels = scipy.stats.mode(labels, axis=-1)[0]\n",
    "labels = np.squeeze(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(20).reshape(4,5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_0:\n",
      "[INFO] finish create model_0\n",
      "model_1:\n",
      "[INFO] finish create model_1\n"
     ]
    }
   ],
   "source": [
    "# Voting Max\n",
    "\n",
    "from keras.layers import average, add\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "def ensemble_model(X_train, n_classes=6, nmodel=3):\n",
    "    models=[]\n",
    "    for i in range(nmodel):\n",
    "        print('model_{}:'.format(i))\n",
    "        model_ = create_3dcnn(X_train,n_classes)\n",
    "        models.append(model_)\n",
    "        print('[INFO] finish create model_{}'.format(i))\n",
    "        \n",
    "\n",
    "    model_inputs = [Input(shape=X_train.shape[1:]) for _ in range (nmodel)]   #定义了一个input层\n",
    "    model_outputs = [models[i](model_inputs[i]) for i in range (nmodel)]   #所有model添加input，models[i](model_inputs[i])Keras API添加模型形式\n",
    "    model_outputs = add(inputs=model_outputs)  #具体模型结构参考plot图像\n",
    "    model = Model(inputs=model_inputs, outputs=model_outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    #model.summary()\n",
    "    #plot_model(model, to_file=\"F://C3D_ensemble.png\", show_shapes=True, show_layer_names=True)\n",
    "    return model\n",
    "model = ensemble_model(X_train, n_classes=6, nmodel=3)\n",
    "\n",
    "def voting_max(model):\n",
    "    # voting ：Predict labels with models\n",
    "    labels = []    \n",
    "    predicts = np.argmax(model.predict(test), axis=1)\n",
    "    labels.append(predicts)\n",
    "\n",
    "    # Ensemble with voting\n",
    "    labels = np.array(labels)\n",
    "    labels = np.transpose(labels, (1, 0))\n",
    "    # mode众数，出现次数最多的\n",
    "    # 有个问题，如果某个类别没有众数，此时该选取哪一个类别？？\n",
    "    labels = scipy.stats.mode(labels, axis=-1)[0]\n",
    "    labels = np.squeeze(labels)\n",
    "    \n",
    "    renturn labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 10, 32, 32, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 10, 32, 32, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 6)            734982      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 6)            734982      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 6)            0           sequential_1[1][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,469,964\n",
      "Trainable params: 1,468,364\n",
      "Non-trainable params: 1,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
